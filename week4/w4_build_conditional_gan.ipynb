{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\n",
    "\n",
    "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \n",
    "\n",
    "### Learning Objectives\n",
    "1.   Learn the technical difference between a conditional and unconditional GAN.\n",
    "2.   Understand the distinction between the class and noise vector in a conditional GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\n",
    "\n",
    "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \n",
    "\n",
    "### Learning Objectives\n",
    "1.   Learn the technical difference between a conditional and unconditional GAN.\n",
    "2.   Understand the distinction between the class and noise vector in a conditional GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f432c1f9f30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor,\n",
    "                       num_images=25,\n",
    "                       size=(1, 28, 28),\n",
    "                       nrow=5,\n",
    "                       show=True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        image_tensor (_type_): _description_\n",
    "        num_images (int, optional): _description_. Defaults to 25.\n",
    "        size (tuple, optional): _description_. Defaults to (1, 28, 28).\n",
    "        nrow (int, optional): _description_. Defaults to 5.\n",
    "        show (bool, optional): _description_. Defaults to True.\n",
    "    \"\"\"\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._generator = nn.Sequential(\n",
    "            self._make_gen_block(input_dim, hidden_dim * 4),\n",
    "            self._make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self._make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self._make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def _make_gen_block(self, input_channels, output_channels, kernel_size, stride, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    \n",
    "    def call(self, noise):\n",
    "        x = noise.view(len(noise), self._input_dim, 1, 1)\n",
    "        return self._generator(x)\n",
    "\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, intput_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self._discriminator = nn.Sequential(\n",
    "            self._make_disc_block(im_chan, hidden_dim),\n",
    "            self._make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self._make_disc_block(hidden_dim * 2, 1, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def _make_disc_block(self, input_channels, output_channels, kernel_size, stride, final_layer=False):\n",
    "        if not final_layer:\n",
    "            nn.Sequential(\n",
    "                nn.Conv2D(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(on2, inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self._discriminator(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Input\n",
    "\n",
    "In conditional GANs, the input vector for the generator will also need to include the class information. The class is represented using a one-hot encoded vector where its length is the number of classes and each index represents a class. The vector is all 0's and a 1 on the chosen class. Given the labels of multiple images (e.g. from a batch) and number of classes, please create one-hot vectors for each label. There is a class within the PyTorch functional library that can help you.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">get_one_hot_labels</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "1.   This code can be done in one line.\n",
    "2.   The documentation for [F.one_hot](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.one_hot) may be helpful.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5)\n",
    "F.one_hot(torch.arange(0, 5), num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_one_hot_labels(labels, n_classes):\n",
    "    return F.one_hot(labels, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert (\n",
    "    get_one_hot_labels(\n",
    "        labels=torch.Tensor([[0, 2, 1]]).long(),\n",
    "        n_classes=3\n",
    "    ).tolist() == \n",
    "    [[\n",
    "      [1, 0, 0], \n",
    "      [0, 0, 1], \n",
    "      [0, 1, 0]\n",
    "    ]]\n",
    ")\n",
    "# Check that the device of get_one_hot_labels matches the input device\n",
    "if torch.cuda.is_available():\n",
    "    assert str(get_one_hot_labels(torch.Tensor([[0]]).long().cuda(), 1).device).startswith(\"cuda\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to be able to concatenate the one-hot class vector to the noise vector before giving it to the generator. You will also need to do this when adding the class channels to the discriminator.\n",
    "\n",
    "To do this, you will need to write a function that combines two vectors. Remember that you need to ensure that the vectors are the same type: floats. Again, you can look to the PyTorch library for help.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">combine_vectors</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "1.   This code can also be written in one line.\n",
    "2.   The documentation for [torch.cat](https://pytorch.org/docs/master/generated/torch.cat.html) may be helpful.\n",
    "3.   Specifically, you might want to look at what the `dim` argument of `torch.cat` does.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5428, -2.2188,  0.2590],\n",
       "         [-1.0297, -0.5008,  0.2734]]),\n",
       " tensor([[-0.9181, -0.0404,  0.2881],\n",
       "         [-0.0075, -0.9145, -1.0886]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(2, 3)\n",
    "x2 = torch.randn(2, 3)\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5428, -2.2188,  0.2590, -0.9181, -0.0404,  0.2881],\n",
       "        [-1.0297, -0.5008,  0.2734, -0.0075, -0.9145, -1.0886]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.cat([x1, x2], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5428, -2.2188,  0.2590],\n",
       "        [-1.0297, -0.5008,  0.2734],\n",
       "        [-0.9181, -0.0404,  0.2881],\n",
       "        [-0.0075, -0.9145, -1.0886]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = torch.cat([x1, x2], axis=0)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vectors(x, y):\n",
    "    return torch.cat([x.float(), y.float()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "combined = combine_vectors(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5, 6], [7, 8]]))\n",
    "if torch.cuda.is_available():\n",
    "    # Check that it doesn't break with cuda\n",
    "    cuda_check = combine_vectors(torch.tensor([[1, 2], [3, 4]]).cuda(), torch.tensor([[5, 6], [7, 8]]).cuda())\n",
    "    assert str(cuda_check.device).startswith(\"cuda\")\n",
    "# Check exact order of elements\n",
    "assert torch.all(combined == torch.tensor([[1, 2, 5, 6], [3, 4, 7, 8]]))\n",
    "# Tests that items are of float type\n",
    "assert (type(combined[0][0].item()) == float)\n",
    "# Check shapes\n",
    "combined = combine_vectors(torch.randn(1, 4, 5), torch.randn(1, 8, 5));\n",
    "assert tuple(combined.shape) == (1, 12, 5)\n",
    "assert tuple(combine_vectors(torch.randn(1, 10, 12).long(), torch.randn(1, 20, 12).long()).shape) == (1, 30, 12)\n",
    "# Check that the float transformation doesn't happen after the inputs are concatenated\n",
    "assert tuple(combine_vectors(torch.randn(1, 10, 12).long(), torch.randn(1, 20, 12)).shape) == (1, 30, 12)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now you can start to put it all together!\n",
    "First, you will define some new parameters:\n",
    "\n",
    "*   mnist_shape: the number of pixels in each MNIST image, which has dimensions 28 x 28 and one channel (because it's black-and-white) so 1 x 28 x 28\n",
    "*   n_classes: the number of classes in MNIST (10, since there are the digits from 0 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
