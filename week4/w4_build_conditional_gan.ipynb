{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\n",
    "\n",
    "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \n",
    "\n",
    "### Learning Objectives\n",
    "1.   Learn the technical difference between a conditional and unconditional GAN.\n",
    "2.   Understand the distinction between the class and noise vector in a conditional GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\n",
    "\n",
    "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \n",
    "\n",
    "### Learning Objectives\n",
    "1.   Learn the technical difference between a conditional and unconditional GAN.\n",
    "2.   Understand the distinction between the class and noise vector in a conditional GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f432c1f9f30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor,\n",
    "                       num_images=25,\n",
    "                       size=(1, 28, 28),\n",
    "                       nrow=5,\n",
    "                       show=True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        image_tensor (_type_): _description_\n",
    "        num_images (int, optional): _description_. Defaults to 25.\n",
    "        size (tuple, optional): _description_. Defaults to (1, 28, 28).\n",
    "        nrow (int, optional): _description_. Defaults to 5.\n",
    "        show (bool, optional): _description_. Defaults to True.\n",
    "    \"\"\"\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._generator = nn.Sequential(\n",
    "            self._make_gen_block(input_dim, hidden_dim * 4),\n",
    "            self._make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self._make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self._make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def _make_gen_block(self, input_channels, output_channels, kernel_size, stride, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "    \n",
    "    def call(self, noise):\n",
    "        x = noise.view(len(noise), self._input_dim, 1, 1)\n",
    "        return self._generator(x)\n",
    "\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, intput_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
