{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mark-Barbaric/Generative-Adversarial-Networks-GANs-Specialization/blob/course1_week4/week4/w4_build_controllable_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix1MDJrforxm"
      },
      "source": [
        "# Build Controllable GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqHQEnaUorxo"
      },
      "source": [
        "### Goals\n",
        "In this notebook, you're going to implement a GAN controllability method using gradients from a classifier. By training a classifier to recognize a relevant feature, you can use it to change the generator's inputs (z-vectors) to make it generate images with more or less of that feature.\n",
        "\n",
        "You will be started you off with a pre-trained generator and classifier, so that you can focus on the controllability aspects. However, in case you would like to train your own classifier, the code for that has been provided as well.\n",
        "\n",
        "### Learning Objectives\n",
        "1. Observe how controllability can change a generator's output.\n",
        "2. Resolve some of the challenges that entangled features pose to controllability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJJTOkjaorxo"
      },
      "source": [
        "## Getting started!\n",
        "\n",
        "You will start off by importing useful libraries and packages and defining a visualization function. You have also been provided with the generator, noise, and classifier code from earlier assignments. The classifier has the same archicture as the earlier critic (remember that the discriminator/critic is simply a classifier used to classify real and fake).\n",
        "\n",
        "#### CelebA\n",
        "For this notebook, instead of the MNIST dataset, you will be using [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). CelebA is a dataset of annotated celebrity images. Since they are colored (not black-and-white), the images have three channels for red, green, and blue (RGB).\n",
        "\n",
        "![celeba](https://github.com/Mark-Barbaric/Generative-Adversarial-Networks-GANs-Specialization/blob/course1_week4/week4/celeba.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SbX1a3lZorxo",
        "outputId": "b7d895f6-9532-4595-a490-f611323c35f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7da1be4f14d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CelebA\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vhvs7IZhsJWQ",
        "outputId": "2560d058-1c4b-49bc-9faa-8610c50f72fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1rZDmvCforxq"
      },
      "outputs": [],
      "source": [
        "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
        "    \"\"\"_summary_ Function for visualizing images\n",
        "    Args:\n",
        "        image_tensor (_type_): _description_\n",
        "        num_images (int, optional): _description_. Defaults to 16.\n",
        "        size (tuple, optional): _description_. Defaults to (3, 64, 64).\n",
        "        nrows (int, optional): _description_. Defaults to 3.\n",
        "    \"\"\"\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[: num_images], nrow=nrow)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4fc-C6Yorxq"
      },
      "source": [
        "### Generator and Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "G531kOwIorxq"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        nn (_type_): _description_\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_generator_block(z_dim, hidden_dim * 8),\n",
        "            self.make_generator_block(hidden_dim * 8, hidden_dim * 4),\n",
        "            self.make_generator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "            self.make_generator_block(hidden_dim * 2, hidden_dim),\n",
        "            self.make_generator_block(hidden_dim, im_chan, kernel_size=4, final_layer=True)\n",
        "        )\n",
        "\n",
        "\n",
        "    def make_generator_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.Tanh()\n",
        "            )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
        "        return self.gen(x)\n",
        "\n",
        "\n",
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    '''\n",
        "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n",
        "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
        "    Parameters:\n",
        "        n_samples: the number of samples in the batch, a scalar\n",
        "        z_dim: the dimension of the noise vector, a scalar\n",
        "        device: the device type\n",
        "    '''\n",
        "    return torch.randn(n_samples, z_dim, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhvp3C2Vorxr"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VMwMrtH-orxr"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    '''\n",
        "    Classifier Class\n",
        "    Values:\n",
        "        im_chan: the number of channels in the images, fitted for the dataset used, a scalar\n",
        "              (CelebA is rgb, so 3 is our default)\n",
        "        n_classes: the total number of classes in the dataset, an integer scalar\n",
        "        hidden_dim: the inner dimension, a scalar\n",
        "    '''\n",
        "    def __init__(self, im_chan=3, n_classes=2, hidden_dim=64):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            self.make_classifier_block(im_chan, hidden_dim),\n",
        "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_classifier_block(hidden_dim * 2, hidden_dim * 4, stride=3),\n",
        "            self.make_classifier_block(hidden_dim * 4, n_classes, final_layer=True)\n",
        "        )\n",
        "\n",
        "    def make_classifier_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
        "        '''\n",
        "        Function to return a sequence of operations corresponding to a classifier block;\n",
        "        a convolution, a batchnorm (except in the final layer), and an activation (except in the final layer).\n",
        "        Parameters:\n",
        "            input_channels: how many channels the input feature representation has\n",
        "            output_channels: how many channels the output feature representation should have\n",
        "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
        "            stride: the stride of the convolution\n",
        "            final_layer: a boolean, true if it is the final layer and false otherwise\n",
        "                      (affects activation and batchnorm)\n",
        "        '''\n",
        "        if final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        class_pred = self.classifier(image)\n",
        "        return class_pred.view(len(class_pred), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKcyDOi4orxr"
      },
      "source": [
        "## Specifying Parameters\n",
        "Before you begin training, you need to specify a few parameters:\n",
        "  *   z_dim: the dimension of the noise vector\n",
        "  *   batch_size: the number of images per forward/backward pass\n",
        "  *   device: the device type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "dLi6H-Ylorxr"
      },
      "outputs": [],
      "source": [
        "z_dim = 64\n",
        "batch_size = 128\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Classifier (Optional)\n",
        "\n",
        "You're welcome to train your own classifier with this code, but you are provided with a pretrained one later in the code. Feel free to skip this code block, and if you do want to train your own classifier, it is recommended that you initially go through the assignment with the provided classifier!"
      ],
      "metadata": {
        "id": "eYV_ReTwowUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(filename):\n",
        "    label_indices = range(40)\n",
        "    n_epochs = 3\n",
        "    display_step = 500\n",
        "    lr = 0.001\n",
        "    beta_1 = 0.5\n",
        "    beta_2 = 0.999\n",
        "    image_size = 64\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.CenterCrop(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "#    dataloader = DataLoader(\n",
        "#        CelebA('.', split='train', download=True, transform=transform),\n",
        "#        batch_size=batch_size,\n",
        "#        shuffle=True\n",
        "#    )\n",
        "    celeb_mnist_data_location = '/AI/data/mnist'\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        CelebA(celeb_mnist_data_location, split='train', download=False, transform=transform),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    classifier = Classifier(n_classes=len(label_indices)).to(device)\n",
        "    class_opt = torch.optim.Adam(classifier.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    cur_step = 0\n",
        "    classifier_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for real, labels in tqdm(dataloader):\n",
        "            real = real.to(device)\n",
        "            labels = labels[:, label_indices].to(device).float()\n",
        "\n",
        "            class_opt.zero_grad()\n",
        "            class_pred = classifier(real)\n",
        "            class_loss = criterion(class_pred, labels)\n",
        "            class_loss.backward()\n",
        "            class_opt.step()\n",
        "            classifier_losses.append(class_loss.item())\n",
        "\n",
        "            if cur_step > 0 and cur_step % display_step == 0:\n",
        "                class_mean = sum(classifier_losses[-display_step:]) / display_step\n",
        "                print(f\"Epoch {epoch}, step {cur_step}, Classifier Loss: {class_mean}\")\n",
        "                step_bins = 20\n",
        "                x_axis = sorted([i * step_bins for i in range(len(classifier_losses) // step_bins)] * step_bins)\n",
        "                sns.lineplot(x_axis, classifier_losses[:len(x_axis)], label='Classifier Loss')\n",
        "                plt.legend()\n",
        "                plt.show()\n",
        "\n",
        "            cur_step += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "Cu-F6NGxowis"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_classifier('classifier')"
      ],
      "metadata": {
        "id": "BjUCZe1DqnHL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_loc = '/content/drive/MyDrive/AI/models/coursera/Generative_Adversarial_Networks/course_1/week_4'"
      ],
      "metadata": {
        "id": "s2HP7ebb8YvQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_dict = torch.load(f\"{pretrained_model_loc}/pretrained_celeba.pth\")['gen']\n",
        "gen.load_state_dict(gen_dict)\n",
        "gen.eval()"
      ],
      "metadata": {
        "id": "NVL5wKxXuNEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2195ca45-8247-4abd-bb0f-86a430252817"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (gen): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): ConvTranspose2d(64, 512, kernel_size=(3, 3), stride=(2, 2))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (1): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 40\n",
        "classifier = Classifier(n_classes=n_classes).to(device)\n",
        "class_dict = torch.load(f\"{pretrained_model_loc}/pretrained_classifier.pth\", map_location=torch.device(device))['classifier']\n",
        "classifier.load_state_dict(class_dict)\n",
        "classifier.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJaBzzDv8Fbf",
        "outputId": "070e5b38-b8bb-42d9-a42f-42db4ec1229e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (classifier): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(3, 3))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 40, kernel_size=(4, 4), stride=(2, 2))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(classifier.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "2QTuuz8S8VWY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Now you can start implementing a method for controlling your GAN!"
      ],
      "metadata": {
        "id": "MZrCHeLx6lhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Update Noise\n",
        "For training, you need to write the code to update the noise to produce more of your desired feature. You do this by performing stochastic gradient ascent. You use stochastic gradient ascent to find the local maxima, as opposed to stochastic gradient descent which finds the local minima. Gradient ascent is gradient descent over the negative of the value being optimized. Their formulas are essentially the same, however, instead of subtracting the weighted value, stochastic gradient ascent adds it; it can be calculated by `new = old + (∇ old * weight)`, where ∇ is the gradient of `old`. You perform stochastic gradient ascent to try and maximize the amount of the feature you want. If you wanted to reduce the amount of the feature, you would perform gradient descent. However, in this assignment you are interested in maximize your feature using gradient ascent, since many features in the dataset are not present much more often than they're present and you are trying to add a feature to the images, not remove.\n",
        "\n",
        "Given the noise with its gradient already calculated through the classifier, you want to return the new noise vector.\n",
        "\n",
        "<details>\n",
        "\n",
        "<summary>\n",
        "<font size=\"3\" color=\"green\">\n",
        "<b>Optional hint for <code><font size=\"4\">calculate_updated_noise</font></code></b>\n",
        "</font>\n",
        "</summary>\n",
        "\n",
        "1.   Remember the equation for gradient ascent: `new = old + (∇ old * weight)`.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "UMKEWTjv6nkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_updated_noise(noise, weight):\n",
        "    new_noise = noise + (weight * noise.grad)\n",
        "    return new_noise"
      ],
      "metadata": {
        "id": "I1okM01K6mBd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt.zero_grad()\n",
        "noise = torch.ones(20, 20) * 2\n",
        "noise.requires_grad_()\n",
        "fake_classes = (noise ** 2).mean()\n",
        "fake_classes.backward()\n",
        "new_noise = calculate_updated_noise(noise, 0.1)\n",
        "assert type(new_noise) == torch.Tensor\n",
        "assert tuple(new_noise.shape) == (20, 20)\n",
        "assert new_noise.max() == 2.0010\n",
        "assert new_noise.min() == 2.0010\n",
        "assert torch.isclose(new_noise.sum(), torch.tensor(0.4) + 20 * 20 * 2)\n",
        "print(\"Success\")"
      ],
      "metadata": {
        "id": "QrOec4__6wzn",
        "outputId": "28ded5f3-6255-48ed-ac74-948d9e5de372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt.zero_grad()\n",
        "noise = get_noise(32, z_dim).to(device).requires_grad_()\n",
        "fake = gen(noise)\n",
        "fake_classes = classifier(fake)[:, 0]\n",
        "fake_classes.mean().backward()\n",
        "noise.data = calculate_updated_noise(noise, 0.01)\n",
        "fake = gen(noise)\n",
        "fake_classes_new = classifier(fake)[:, 0]\n",
        "assert torch.all(fake_classes_new > fake_classes)\n",
        "print(\"Success\")"
      ],
      "metadata": {
        "id": "kETwvRtE97F1",
        "outputId": "6903114a-22c8-447e-bab9-2c8f99d0bc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generation\n",
        "Now, you can use the classifier along with stochastic gradient ascent to make noise that generates more of a certain feature. In the code given to you here, you can generate smiling faces. Feel free to change the target index and control some of the other features in the list! You will notice that some features are easier to detect and control than others.\n",
        "\n",
        "The list you have here are the features labeled in CelebA, which you used to train your classifier. If you wanted to control another feature, you would need to get data that is labeled with that feature and train a classifier on that feature."
      ],
      "metadata": {
        "id": "WyFjT4gD-weF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6b8YL3v_-S85"
      },
      "execution_count": 57,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}